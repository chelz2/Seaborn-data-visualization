{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9860b1",
   "metadata": {},
   "source": [
    "# Distribution plots in Seaborn\n",
    "\n",
    "- understanding different distribution plot types & their concepts \n",
    "\n",
    "> distribution plot types represents a single continuos feature (dtype that can be broken down into smaller & smaller chunks) and help visualize statistic properties like deviation & average value mean\n",
    "\n",
    ">3 main distribution plot types & they are built off each other - \n",
    "\n",
    "- Rug plot \n",
    "- Histogram\n",
    "- KDE plot ( kernel density estimation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffefdd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rug plot ---> eg- explore distribution of employee salaries using Rug plot\n",
    "\n",
    "#---> it is the simplest distribution plots, all it does is simply adds a dash or tick line for every single value\n",
    "\n",
    "\n",
    "#---> NB - i.e, Y-axis dont have a meaning in Rug plots\n",
    "\n",
    "#--> i.e all it does is add a single line for every single instance value (eg - salary) along horizantal X-axis & we can adjust the height of line/tick we want\n",
    "\n",
    "\n",
    "#--> *problem with Rug plot is Y-axis is not interpretable as it represents nothing\n",
    "\n",
    "\n",
    "#--> *nice thing about Rug plot is we can immediately see the outliers, eg- highest & lowest salary & we can also most salary range  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c7bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram Plot ---> **** i.e we convert Rug plot to a Histogram plot\n",
    "\n",
    "#----> more interpretable &  build directly off the rug plot\n",
    "\n",
    "#---> i.e, if we count how many ticks/lines there are per various X-ranges, then we can create a histogram\n",
    "\n",
    "#---> eg - how many ticks between 40K & 50K, 50K & 60K, and so on .....\n",
    "\n",
    "##### STEPS :-\n",
    "\n",
    "#---> we first choose number *bins --> i.e how many chunks will we cut X-axis into *AND this bins should be of the same size\n",
    "\n",
    "                # eg -- all bins in size of 10 units of x-axis each\n",
    "\n",
    "#---> & then  we count the number of ticks there are per bin & we create the *BAR as high as the count of the ticks \n",
    "\n",
    "#---> i.e , for each *BINS we count how many ticks there are & then we create the *BAR as high as count in each *BINS\n",
    "\n",
    "#---> i.e we can check the heights of the bar to see the number of instances in bin \n",
    "\n",
    "#---> i.e, we have now an interpretable Y-axis & we have a clear visualization of distribution\n",
    "\n",
    "#---> i.e if we want to know how many pts is there between ranges then we can check the the height of our bar\n",
    "\n",
    "\n",
    "###### # Noramlize the Y-axis ---> i.e we can normalize the y-axis of the histogram plot as a percent if we want :-\n",
    "\n",
    "#---> i.e, sometimes peaple shows the y-axis as the actual count & sometimes we can see it as a percentage of all the instrances\n",
    "\n",
    "\n",
    "# ---> we can also change no. of bins to show more detail & variant instead of general trend\n",
    "\n",
    "# But* - if we go too high in our bin count then there will be certain bins (x-axis) which ll be completely empty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e924e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE ---> Kernal Density Estimation plot\n",
    "\n",
    "# ----> i.e seaborn allows to also add on a KDE plot curve on top of the Histogram\n",
    "\n",
    "#-----> this shows how a continous probability will look like for that particular continiuos datasets\n",
    "\n",
    "#----> i.e it is a method for estimating probability density function of a random variable\n",
    "\n",
    "#----> all this (KDE) mean is a way of estimating a continous probability curve for a finite data sample\n",
    "\n",
    "#---> eg - i.e theoratically we dont know every single pt for every single salary in histogram  as  far as probabilty of someone \n",
    "        # in a larger sample having as salary between 60K & 65K since we are dealing with finite datasets\n",
    "    \n",
    "    \n",
    "    # i.e this curve line KDE allows us to behave as if we are dealing with a continous probability curve when in reality we \n",
    "    # are just dealing with discrete measurement of a finite datasets\n",
    "    \n",
    "    #---> KDE plots are best understood by visualizing its construction\n",
    "    \n",
    "    #---> we first start with a Rug plot, i.e we take some continuos feature datasets which can be positve , negative or both\n",
    "    \n",
    "    #--->then we decide what kernel we are going to use, i.e what probability distribution do we want to stack on top of each \n",
    "        #this ticks in Rug plot\n",
    "        \n",
    "        #----> most common KDE to use is Gaussian distribution (also clal Normal distribution)\n",
    "        \n",
    "        #----> we stack norammal distribution on top of each of the tick/line, i.e each tick has gaussian curve which is centered \n",
    "             # at that tick\n",
    "            \n",
    "        #----> then to build overall curve we add all this normal distribution curve & we end up wit this KDE \n",
    "             # (Kernel Density Estimation) plot which is essentially telling is the probability as if it was a continuos distribution.\n",
    "            \n",
    "        # Thus, we have this continious KDE curve & we were able to build it off a finite datasets, which is another way of showing\n",
    "         # the distribution of continuos feature\n",
    "            \n",
    "            \n",
    "        # NB -> because of the way this KDE curve is constructed, ther is ability/chances to go beyond original dataset.\n",
    "             #--> it can leak pass both the LHS & RHS of the original dataset \n",
    "            \n",
    "            #---> we ll get a probality for values not in datasets which may or maynot be true depending on what datasets we are \n",
    "                 # working on\n",
    "                \n",
    "            #---> NB - i.e we do a hard cutt off at both LHS value & RHS value in such case\n",
    "            \n",
    "               # eg - for salary dataset we cut off the curve at zero as we cannot have negative salary\n",
    "                \n",
    "        \n",
    "        #NB --> we can also change the kernel, i.e it dont have tobe gausian kernel \n",
    "            #--> we can also change the bandwidth which can make our KDE show more or less of the variance contain in the data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732e6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
